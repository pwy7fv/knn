{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f7ef20f0-722f-4240-8a79-437d4a3b8832",
      "metadata": {
        "id": "f7ef20f0-722f-4240-8a79-437d4a3b8832"
      },
      "source": [
        "## Assignment 3: $k$ Nearest Neighbor\n",
        "\n",
        "**Do two questions.**\n",
        "\n",
        "`! git clone https://github.com/DS3001/knn`"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q0.\n",
        "\n",
        "1. What is the difference between regression and classification?\n",
        "2. What is a confusion table? What does it help us understand about a model's performance?\n",
        "3. What does the SSE quantify about a particular model?\n",
        "4. What are overfitting and underfitting?\n",
        "5. Why does splitting the data into training and testing sets, and choosing\n",
        " by evaluating accuracy or SSE on the test set, improve model performance?\n",
        "6. With classification, we can report a class label as a prediction or a probability distribution over class labels. Please explain the strengths and weaknesses of each approach."
      ],
      "metadata": {
        "id": "DZ1LehFDF2Qu"
      },
      "id": "DZ1LehFDF2Qu"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rnx0m5JqGCjL"
      },
      "id": "rnx0m5JqGCjL"
    },
    {
      "cell_type": "markdown",
      "id": "71c9e0b8-17f5-4ff9-9c76-2034bffe8d5c",
      "metadata": {
        "id": "71c9e0b8-17f5-4ff9-9c76-2034bffe8d5c"
      },
      "source": [
        "**Q1.**  This question is a case study for k\n",
        " nearest neighbor regression, using the USA_cars_datasets.csv data.\n",
        "\n",
        "This question is a case study for $k$ nearest neighbor The target variable `y` is `price` and the features are `year` and `mileage`.\n",
        "\n",
        "1. Load the `./data/USA_cars_datasets.csv`. Keep the following variables and drop the rest: `price`, `year`, `mileage`. Are there any `NA`'s to handle? Look at the head and dimensions of the data.\n",
        "2. Maxmin normalize `year` and `mileage`.\n",
        "3. Split the sample into ~80% for training and ~20% for evaluation.\n",
        "4. Use the $k$NN algorithm and the training data to predict `price` using `year` and `mileage` for the test set for $k=3,10,25,50,100,300$. For each value of $k$, compute the mean squared error and print a scatterplot showing the test value plotted against the predicted value. What patterns do you notice as you increase $k$?\n",
        "5. Determine the optimal $k$ for these data.\n",
        "6. Describe what happened in the plots of predicted versus actual prices as $k$ varied, taking your answer into part 6 into account. (Hint: Use the words \"underfitting\" and \"overfitting\".)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. This is a case study on k\n",
        " nearest neighbor classification, using the animals.csv data.\n",
        "\n",
        "The data consist of a label, class, taking integer values 1 to 7, the name of the species, animal, and 16 characteristics of the animal, including hair, feathers, milk, eggs, airborne, and so on.\n",
        "\n",
        "1. Load the data. For each of the seven class labels, print the values in the class and get a sense of what is included in that group. Perform some other EDA: How big are the classes? How much variation is there in each of the features/covariates? Which variables do you think will best predict which class?\n",
        "2. Split the data 50/50 into training and test/validation sets. (The smaller the data are, the more equal the split should be, in my experience: Otherwise, all of the members of one class end up in the training or test data, and the model falls apart.)\n",
        "3. Using all of the variables, build a\n",
        "k-NN classifier. Explain how you select k\n",
        "4. Print a confusion table for the optimal model, comparing predicted and actual class label on the test set. How accurate it is? Can you interpret why mistakes are made across groups?\n",
        "5. Use only milk, aquatic, and airborne to train a new\n",
        "k-NN classifier. Print your confusion table. Mine does not predict all of the classes, only a subset of them. To see the underlying probabilities, use model.predict_proba(X_test.values) to predict probabilities rather than labels for your X_test test data for your fitted model. Are all of the classes represented? Explain your results."
      ],
      "metadata": {
        "id": "2N-pHlT_GndL"
      },
      "id": "2N-pHlT_GndL"
    },
    {
      "cell_type": "markdown",
      "id": "010b57f7-bf4f-4494-b54c-49c4f3ae3ab9",
      "metadata": {
        "id": "010b57f7-bf4f-4494-b54c-49c4f3ae3ab9"
      },
      "source": [
        "**Q5.** This question is a case study for $k$ nearest neighbor, using the heart_failure_clinical_records_dataset.csv data.\n",
        "\n",
        "\n",
        "\n",
        "The data for the question include:\n",
        "\n",
        "- age: age of the patient (years)\n",
        "- anaemia: decrease of red blood cells or hemoglobin (boolean)\n",
        "- high blood pressure: if the patient has hypertension (boolean)\n",
        "- creatinine phosphokinase (CPK): level of the CPK enzyme in the blood (mcg/L)\n",
        "- diabetes: if the patient has diabetes (boolean)\n",
        "- ejection fraction: percentage of blood leaving the heart at each contraction (percentage)\n",
        "- platelets: platelets in the blood (kiloplatelets/mL)\n",
        "- sex: woman or man (binary)\n",
        "- serum creatinine: level of serum creatinine in the blood (mg/dL)\n",
        "- serum sodium: level of serum sodium in the blood (mEq/L)\n",
        "- smoking: if the patient smokes or not (boolean)\n",
        "- time: follow-up period (days)\n",
        "- death event: if the patient deceased during the follow-up period (boolean)\n",
        "\n",
        "1. Load the `./data/heart_failure_clinical_records_dataset.csv`. Are there any `NA`'s to handle? use `.drop()` to remove `time` from the dataframe.\n",
        "2. Make a correlation matrix. What variables are strongly associated with a death event?\n",
        "3. For the dummy variables `anaemia`, `diabetes`, `high_blood_pressure`, `sex`, and `smoking`, compute a summary table of `DEATH_EVENT` grouped by the variable. For which variables does a higher proportion of the population die when the variable takes the value 1 rather than 0?\n",
        "4. On the basis of your answers from 2 and 3, build a matrix $X$ of the variables you think are most predictive of a death, and a variable $y$ equal to `DEATH_EVENT`.\n",
        "5. Maxmin normalize all of the variables in `X`.\n",
        "6. Split the sample into ~80% for training and ~20% for evaluation. (Try to use the same train/test split for the whole question, so that you're comparing apples to apples in the questions below.).\n",
        "7. Determine the optimal number of neighbors for a $k$NN regression for the variables you selected.\n",
        "8. OK, do steps 5 through 7 again, but use all of the variables (except `time`). Which model has a lower Sum of Squared Error? Which would you prefer to use in practice, if you had to predict `DEATH_EVENT`s? If you play with the selection of variables, how much does the SSE change for your fitted model on the test data? Are more variables always better? Explain your findings."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d457e190-d273-455f-b94f-62916cb5af1c",
      "metadata": {
        "id": "d457e190-d273-455f-b94f-62916cb5af1c"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}